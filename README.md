<img width="100%" src="https://github.com/JoshuaThadi/Generative-AI/blob/main/assests/banner.png">

## ★ Generative AI

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Topics Covered in Generative AI

<b>1] Fundamentals of Generative AI</b> : Learn how AI models create new data like text, images, audio, and more from patterns in training data. <br>
<b>2] Text, Image, Audio, Video, and Code Generation</b> : Explore how AI systems generate content across multiple modalities using deep learning techniques. <br>
<b>3] GANs (Generative Adversarial Networks)</b> : Use two neural networks in competition to produce highly realistic synthetic data. <br>
<b>4] VAEs (Variational Autoencoders)</b> : Learn how VAEs encode data into a latent space and decode it for controlled and smooth data generation. <br>
<b>5] Diffusion Models</b> : Generate high-quality images by reversing a noise-based degradation process through iterative denoising. <br>
<b>6] Transformers</b> : Foundation of modern generative AI, leveraging self-attention for sequential data generation in models like GPT and BERT. <br>
<b>7] Deepfakes and Ethics</b> : Understand the ethical implications and risks of synthetic media that mimics real people or voices. <br>
<b>8] BLEU (Bilingual Evaluation Understudy)</b> : Measures n-gram overlap between generated and reference text, often used in machine translation. <br>
<b>9] ROUGE (Recall-Oriented Understudy for Gisting Evaluation)</b> : Evaluates the recall of overlapping phrases in generated summaries compared to references. <br>
<b>10] FID (Fréchet Inception Distance)</b> : Quantifies image quality by comparing the feature distribution of real and generated images. <br>
<b>11] Inception Score</b> : Evaluates image generation by assessing both object recognizability and output diversity. <br>
<b>12] Applications in Art, Music, Content, Code, Avatars</b> : Generative AI is driving innovation in creativity, enabling tools for art, music composition, coding, and virtual avatars. <br>

<!-- 1. Fundamentals of Generative AI -->
<a href="https://www.deeplearning.ai/short-courses/generative-ai-with-llms/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Fundamentals_of_Generative_AI-555555?style=for-the-badge&logo=OpenAI&logoColor=white" alt="Fundamentals of Generative AI"></a>

<!-- 2. Multimodal Generation -->
<a href="https://platform.openai.com/examples" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Text_Image_Audio_Video_Code_Generation-555555?style=for-the-badge&logo=OpenAI&logoColor=white" alt="Multimodal Generation"></a>

<!-- 3. GANs -->
<a href="https://keras.io/examples/generative/dcgan_overriding_train_step/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/GANs_(Generative_Adversarial_Networks)-555555?style=for-the-badge&logo=keras&logoColor=white" alt="GANs"></a>

<!-- 4. VAEs -->
<a href="https://keras.io/examples/generative/vae/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/VAEs_(Variational_Autoencoders)-555555?style=for-the-badge&logo=keras&logoColor=white" alt="VAEs"></a>

<!-- 5. Diffusion Models -->
<a href="https://huggingface.co/docs/diffusers/index" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Diffusion_Models-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Diffusion Models"></a>

<!-- 6. Transformers -->
<a href="https://huggingface.co/transformers/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Transformers-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Transformers"></a>

<!-- 7. Deepfakes and Ethics -->
<a href="https://www.nist.gov/news-events/news/2023/03/nist-seeks-comment-ai-generated-deepfakes-and-manipulated-media" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Deepfakes_&_Ethics-555555?style=for-the-badge&logo=datadog&logoColor=white" alt="Deepfakes and Ethics"></a>

<!-- 8.1 BLEU -->
<a href="https://en.wikipedia.org/wiki/BLEU" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/BLEU_Score-555555?style=for-the-badge&logo=wikidata&logoColor=white" alt="BLEU Score"></a>

<!-- 8.2 ROUGE -->
<a href="https://en.wikipedia.org/wiki/ROUGE_(metric)" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/ROUGE_Score-555555?style=for-the-badge&logo=wikidata&logoColor=white" alt="ROUGE Score"></a>

<!-- 8.3 FID -->
<a href="https://github.com/mseitzer/pytorch-fid" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/FID_(Fréchet_Inception_Distance)-555555?style=for-the-badge&logo=pytorch&logoColor=white" alt="FID"></a>

<!-- 8.4 Inception Score -->
<a href="https://arxiv.org/abs/1606.03498" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Inception_Score-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="Inception Score"></a>

<!-- 9. Applications -->
<a href="https://openai.com/sora" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Generative_AI_Applications-555555?style=for-the-badge&logo=artstation&logoColor=white" alt="Generative AI Applications"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>


### Tools & Frameworks for Generative AI

<b>1] Hugging Face Transformers</b> : A leading library for using and training state-of-the-art NLP and multimodal transformer models.<br>
<b>2] Diffusers</b> : A Hugging Face library for implementing diffusion models for high-quality image and media generation.<br>
<b>3] OpenAI API</b> : Provides access to GPT, DALL·E, Whisper, and other powerful foundation models via API.<br>
<b>4] Runway ML</b> : A no-code platform for creatives to use generative AI models in design, art, and video.<br>
<b>5] Gradio</b> : Simplifies ML model deployment by allowing developers to build interactive UIs in just a few lines of code.<br>
<b>6] Replicate</b> : Enables running and sharing ML models in the cloud without infrastructure setup.<br>
<b>7] TensorFlow</b> : An open-source deep learning framework for building and training scalable machine learning models.<br>
<b>8] PyTorch</b> : A flexible and developer-friendly deep learning library widely used for research and production.<br>


<!-- Hugging Face Transformers -->
<a href="https://huggingface.co/transformers" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Hugging_Face_Transformers-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face Transformers"></a>

<!-- Diffusers -->
<a href="https://huggingface.co/docs/diffusers" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Diffusers-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Diffusers"></a>

<!-- OpenAI API -->
<a href="https://platform.openai.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_API-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI API"></a>

<!-- Runway ML -->
<a href="https://runwayml.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Runway_ML-555555?style=for-the-badge&logo=vercel&logoColor=white" alt="Runway ML"></a>

<!-- Gradio -->
<a href="https://gradio.app/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Gradio-555555?style=for-the-badge&logo=python&logoColor=white" alt="Gradio"></a>

<!-- Replicate -->
<a href="https://replicate.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Replicate-555555?style=for-the-badge&logo=cloudflare&logoColor=white" alt="Replicate"></a>

<!-- TensorFlow -->
<a href="https://www.tensorflow.org/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/TensorFlow-555555?style=for-the-badge&logo=tensorflow&logoColor=white" alt="TensorFlow"></a>

<!-- PyTorch -->
<a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/PyTorch-555555?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Official Resources for Generative AI

<!-- DeepLearning.AI - Generative AI with LLMs -->
<a href="https://www.deeplearning.ai/short-courses/generative-ai-with-llms/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/DeepLearning.AI_Generative_AI-555555?style=for-the-badge&logo=deeplearningai&logoColor=white" alt="DeepLearning.AI Generative AI"></a>

<!-- Hugging Face Course - Diffusers and Transformers -->
<a href="https://huggingface.co/course/chapter7" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/HuggingFace_Course-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face Course"></a>

<!-- OpenAI API Documentation -->
<a href="https://platform.openai.com/docs" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_API_Docs-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI API Docs"></a>

<!-- Fast.ai - Practical Deep Learning for Coders -->
<a href="https://course.fast.ai/part2" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Fast.ai_Deep_Learning-555555?style=for-the-badge&logo=fastapi&logoColor=white" alt="Fast.ai Deep Learning"></a>

<!-- MIT Deep Learning Lectures -->
<a href="https://deeplearning.mit.edu/lectures/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/MIT_Deep_Learning-555555?style=for-the-badge&logo=mit&logoColor=white" alt="MIT Deep Learning Lectures"></a>

<!-- Google AI Blog - Diffusion Models -->
<a href="https://ai.googleblog.com/2021/07/introducing-diffusion-models.html" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_AI_Blog-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google AI Blog"></a>

<!-- Papers with Code - Generative Models -->
<a href="https://paperswithcode.com/task/generative-models" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Papers_with_Code-555555?style=for-the-badge&logo=read-the-docs&logoColor=white" alt="Papers with Code"></a>


<!-- NVIDIA Deep Learning Institute -->
<a href="https://developer.nvidia.com/deep-learning-institute" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/NVIDIA_Deep_Learning_Institute-555555?style=for-the-badge&logo=nvidia&logoColor=white" alt="NVIDIA Deep Learning Institute"></a>

<!-- Google AI Courses -->
<a href="https://ai.google/education/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_AI_Education-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google AI Education"></a>

<!-- Udemy Machine Learning Courses -->
<a href="https://www.udemy.com/topic/machine-learning/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Udemy_Machine_Learning-555555?style=for-the-badge&logo=udemy&logoColor=white" alt="Udemy Machine Learning"></a>

<!-- Coursera Machine Learning by Andrew Ng -->
<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Coursera_Andrew_Ng_ML-555555?style=for-the-badge&logo=coursera&logoColor=white" alt="Coursera Andrew Ng ML"></a>

<!-- Coursera Deep Learning Specialization -->
<a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Coursera_Deep_Learning_Specialization-555555?style=for-the-badge&logo=coursera&logoColor=white" alt="Coursera Deep Learning Specialization"></a>

<!-- Fast.ai Practical Deep Learning -->
<a href="https://course.fast.ai/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Fast.ai_Practical_DL-555555?style=for-the-badge&logo=fastapi&logoColor=white" alt="Fast.ai Practical Deep Learning"></a>



---

## ☆ Large Language Models (LLMs)

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Topics Covered in LLMs

<b>1] Transformer Architecture & Self-Attention</b> : Core deep learning model using attention to process sequences efficiently and capture context.<br>
<b>2] Pretraining & Fine-tuning (LoRA, PEFT, RLHF)</b> : Techniques to adapt large models for specific tasks by efficient training and reinforcement learning.<br>
<b>3] Prompt Engineering (Zero-shot, Few-shot, CoT)</b> : Designing effective input prompts to guide language models’ responses without extensive retraining.<br>
<b>4] Evaluation Metrics (Perplexity, LAMBADA, TruthfulQA)</b> : Quantitative measures to assess language model performance and truthfulness on complex tasks.<br>
<b>5] Model Deployment, Scalability, and Cost Estimation</b> : Strategies to efficiently serve models at scale while managing computational resources and expenses.<br>
<b>6] RAG (Retrieval Augmented Generation)</b> : Combining retrieval systems with generative models to improve answer accuracy using external knowledge.<br>
<b>7] Ethics: Hallucination, Security, Jailbreaking</b> : Addressing risks of misinformation, system vulnerabilities, and adversarial exploitation in AI models.<br>

<!-- Transformer Architecture & Self-Attention -->
<a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Transformer_Architecture-555555?style=for-the-badge&logo=visualstudiocode&logoColor=white" alt="Transformer Architecture"></a>

<!-- Pretraining & Fine-tuning (LoRA, PEFT, RLHF) -->
<a href="https://huggingface.co/blog/peft" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Pretraining_&_Fine-tuning-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Pretraining and Fine-tuning"></a>

<!-- Prompt Engineering (Zero-shot, Few-shot, CoT) -->
<a href="https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/prompt-engineering" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Prompt_Engineering-555555?style=for-the-badge&logo=microsoftazure&logoColor=white" alt="Prompt Engineering"></a>

<!-- Evaluation Metrics (Perplexity, LAMBADA, TruthfulQA) -->
<a href="https://aclanthology.org/2021.naacl-main.364/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Evaluation_Metrics-555555?style=for-the-badge&logo=researchgate&logoColor=white" alt="Evaluation Metrics"></a>

<!-- Model Deployment, Scalability, and Cost Estimation -->
<a href="https://www.tensorflow.org/tfx/guide/serving" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Model_Deployment-555555?style=for-the-badge&logo=tensorflow&logoColor=white" alt="Model Deployment"></a>

<!-- RAG (Retrieval Augmented Generation) -->
<a href="https://huggingface.co/blog/rag" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/RAG_Retrieval_Augmented_Generation-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="RAG"></a>

<!-- Ethics: Hallucination, Security, Jailbreaking -->
<a href="https://ai.google/responsibilities/responsible-ai-practices/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Ethics_in_AI-555555?style=for-the-badge&logo=google&logoColor=white" alt="AI Ethics"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Tools & Frameworks for LLMs

<b>1] Hugging Face Models</b> : Offers thousands of open-source pre-trained models for NLP, vision, audio, and more.<br>
<b>2] LangChain</b> : A framework to build LLM-powered apps by chaining prompts, tools, and memory together.<br>
<b>3] OpenAI GPT-3.5/4</b> : Leading proprietary large language models with world-class reasoning and generation capabilities.<br>
<b>4] Meta LLaMA 2 / 3</b> : Open-weight transformer models built by Meta for research and commercial use.<br>
<b>5] Claude (Anthropic)</b> : Constitutional AI-based LLM with strong reasoning, harmlessness, and helpfulness principles.<br>
<b>6] Google Gemini</b> : Multimodal foundation model from DeepMind capable of text, vision, and code understanding.<br>
<b>7] Mistral AI</b> : Efficient, high-performance open-weight LLMs optimized for real-world deployment.<br>
<b>8] Haystack</b> : Powerful framework for building retrieval-augmented generation (RAG) pipelines using LLMs.<br>

<!-- Hugging Face Models -->
<a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Hugging_Face_Models-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face Models"></a>

<!-- LangChain -->
<a href="https://www.langchain.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/LangChain_Framework-555555?style=for-the-badge&logo=chainlink&logoColor=white" alt="LangChain"></a>

<!-- OpenAI GPT-3.5/4 -->
<a href="https://platform.openai.com/docs" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_GPT_3.5/4-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI GPT"></a>

<!-- Meta LLaMA 2 / 3 -->
<a href="https://ai.meta.com/llama/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Meta_LLaMA_2/3-555555?style=for-the-badge&logo=meta&logoColor=white" alt="Meta LLaMA"></a>

<!-- Claude (Anthropic) -->
<a href="https://www.anthropic.com/index/claude" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Claude_(Anthropic)-555555?style=for-the-badge&logo=anthropic&logoColor=white" alt="Claude"></a>

<!-- Google Gemini -->
<a href="https://deepmind.google/technologies/gemini/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_Gemini-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini"></a>

<!-- Mistral AI -->
<a href="https://mistral.ai/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Mistral_AI-555555?style=for-the-badge&logo=airbnb&logoColor=white" alt="Mistral AI"></a>

<!-- Haystack -->
<a href="https://haystack.deepset.ai/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Haystack_RAG_Framework-555555?style=for-the-badge&logo=elasticstack&logoColor=white" alt="Haystack"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Official Resources for LLMs

<!-- Hugging Face NLP Course -->
<a href="https://huggingface.co/learn/nlp-course/chapter1" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/HuggingFace_NLP_Course-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face NLP Course"></a>

<!-- Stanford CS25 Transformers Course -->
<a href="https://web.stanford.edu/class/cs25/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Stanford_CS25_Transformers-555555?style=for-the-badge&logo=academia&logoColor=white" alt="Stanford CS25 Transformers"></a>

<!-- Andrej Karpathy – Neural Networks Zero to Hero -->
<a href="https://www.youtube.com/playlist?list=PLpzmRsG7u_gta8p3WGuUq4I1R9apS8Wlg" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Karpathy_Zero_to_Hero-555555?style=for-the-badge&logo=youtube&logoColor=white" alt="Karpathy Zero to Hero"></a>

<!-- Karpathy – Neural Networks Zero to Hero -->
<a href="https://www.youtube.com/playlist?list=PLpzmRsG7u_gta8p3WGuUq4I1R9apS8Wlg" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Karpathy_Zero_to_Hero-555555?style=for-the-badge&logo=youtube&logoColor=white" alt="Karpathy LLM Series"></a>

<!-- OpenAI Cookbook -->
<a href="https://github.com/openai/openai-cookbook" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_Cookbook-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI Cookbook"></a>

<!-- LangChain Documentation -->
<a href="https://docs.langchain.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/LangChain_Docs-555555?style=for-the-badge&logo=chainlink&logoColor=white" alt="LangChain Documentation"></a>

<!-- Anthropic Claude API Docs -->
<a href="https://docs.anthropic.com/claude" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Claude_API_Docs-555555?style=for-the-badge&logo=anthropic&logoColor=white" alt="Claude API Docs"></a>


---

## ✪ Language and Communication Models (LCMs)

Welcome to the **Language and Communication Models (LCMs)** section of the repository. LCMs are a broader class of AI models that go beyond text-based LLMs to encompass **speech**, **dialogue**, **emotion**, and **multimodal communication** — bringing machines closer to truly human-like interaction.

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Core Concepts – Foundations of Human-AI Communication

<b>1] Language vs. Communication Models</b> : Understanding the distinction between structured language models and broader human communication patterns.<br>
<b>2] Speech, Text, and Emotion as Modalities</b> : Key modalities processed by AI to understand and generate human-like interactions.<br>
<b>3] Pragmatics, Semantics, and Context-awareness</b> : How AI interprets meaning, tone, and context beyond literal text.<br>

<!-- Language vs. Communication Models -->
<a href="https://en.wikipedia.org/wiki/Language_model" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Language_vs_Communication-555555?style=for-the-badge&logo=wikipedia&logoColor=white" alt="Language vs Communication Models"></a>

<!-- Speech, Text, and Emotion as Modalities -->
<a href="https://www.sciencedirect.com/topics/computer-science/multimodal-communication" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Speech_Text_Emotion-555555?style=for-the-badge&logo=sciencedirect&logoColor=white" alt="Speech, Text, and Emotion Modalities"></a>

<!-- Pragmatics, Semantics, and Context-awareness -->
<a href="https://plato.stanford.edu/entries/pragmatics/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Pragmatics_Semantics_Context-555555?style=for-the-badge&logo=stanford&logoColor=white" alt="Pragmatics, Semantics, Context-awareness"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Communication Systems – Speech, Dialogue & Emotion Interfaces

<b>1] Conversational AI & Dialogue Systems</b> : AI agents designed to engage in meaningful, coherent conversations with users.<br>
<b>2] Speech-to-Text (ASR)</b> : Converts spoken audio into textual data for analysis and response.<br>
<b>3] Text-to-Speech (TTS)</b> : Converts written text into natural-sounding human speech.<br>
<b>4] Emotion & Sentiment Recognition</b> : Detects affective states in voice or text to tailor responses.<br>
<b>5] Multimodal Language Understanding</b> : Combines input like video, audio, and text to enable richer AI understanding.<br>

<!-- Conversational AI & Dialogue Systems -->
<a href="https://cloud.google.com/dialogflow" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Conversational_AI-555555?style=for-the-badge&logo=google&logoColor=white" alt="Conversational AI & Dialogue Systems"></a>

<!-- Speech-to-Text (ASR) -->
<a href="https://cloud.google.com/speech-to-text" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Speech_to_Text_ASR-555555?style=for-the-badge&logo=google&logoColor=white" alt="Speech-to-Text ASR"></a>

<!-- Text-to-Speech (TTS) -->
<a href="https://cloud.google.com/text-to-speech" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Text_to_Speech_TTS-555555?style=for-the-badge&logo=google&logoColor=white" alt="Text-to-Speech TTS"></a>

<!-- Emotion & Sentiment Recognition -->
<a href="https://www.affectiva.com/emotion-ai/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Emotion_Sentiment_AI-555555?style=for-the-badge&logo=affectiva&logoColor=white" alt="Emotion & Sentiment Recognition"></a>

<!-- Multimodal Language Understanding -->
<a href="https://arxiv.org/abs/2206.10467" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Multimodal_Language_Understanding-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="Multimodal Language Understanding"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Architectures and Techniques – State-of-the-art AI for Audio & Multimodal Tasks

<b>1] Transformer-based speech models</b> : Models using self-attention to process audio sequences effectively.<br>
<b>2] Audio Transformers (Whisper, SpeechT5)</b> : Advanced models designed for speech recognition, translation, and synthesis.<br>
<b>3] Multimodal Fusion (Gemini, GPT-4o, SeamlessM4T)</b> : Combines modalities (audio, visual, text) in a single unified model.<br>
<b>4] Reinforcement Learning for Dialog Control</b> : Uses reward mechanisms to optimize interactive conversations.<br>
<b>5] Attention-based ASR/TTS systems</b> : Employs attention mechanisms for accurate speech recognition and synthesis.<br>


<!-- Transformer-based speech models -->
<a href="https://arxiv.org/abs/2103.02051" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Transformer_Speech_Models-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="Transformer-based Speech Models"></a>

<!-- Audio Transformers (Whisper, SpeechT5) -->
<a href="https://github.com/openai/whisper" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_Whisper-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI Whisper"></a>
<a href="https://huggingface.co/microsoft/speecht5_tts" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/SpeechT5_(HuggingFace)-555555?style=for-the-badge&logo=microsoft&logoColor=white" alt="SpeechT5"></a>

<!-- Multimodal Fusion (Gemini, GPT-4o, SeamlessM4T) -->
<a href="https://deepmind.google/technologies/gemini/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_Gemini-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini"></a>
<a href="https://ai.meta.com/research/publications/seamless-m4t/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Meta_SeamlessM4T-555555?style=for-the-badge&logo=meta&logoColor=white" alt="SeamlessM4T"></a>

<!-- Reinforcement Learning for Dialog Control -->
<a href="https://arxiv.org/abs/2006.12367" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Reinforcement_Learning_Dialog-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="RL for Dialog Control"></a>

<!-- Attention-based ASR/TTS systems -->
<a href="https://arxiv.org/abs/1506.07503" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Attention_ASR_TTS-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="Attention-based ASR/TTS"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Evaluation – How We Measure Communication AI

<b>1] Naturalness and Fluency of Speech</b> : Evaluates how human-like and fluid the generated speech sounds.<br>
<b>2] Emotion Detection Accuracy</b> : Measures how well the model captures human emotional states.<br>
<b>3] BLEU, METEOR, BERTScore</b> : Text-level evaluation metrics for measuring generated vs. reference quality.<br>
<b>4] Human Evaluation: Engagement & Clarity</b> : Real-user feedback to judge interaction quality and coherence.<br>

<!-- Naturalness and Fluency of Speech -->
<a href="https://ieeexplore.ieee.org/document/8938133" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Naturalness_and_Fluency-555555?style=for-the-badge&logo=ieee&logoColor=white" alt="Naturalness and Fluency of Speech"></a>

<!-- Emotion Detection Accuracy -->
<a href="https://ieeexplore.ieee.org/document/8570153" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Emotion_Detection_Accuracy-555555?style=for-the-badge&logo=ieee&logoColor=white" alt="Emotion Detection Accuracy"></a>

<!-- BLEU Score -->
<a href="https://aclweb.org/anthology/P02-1040" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/BLEU_Score-555555?style=for-the-badge&logo=acl&logoColor=white" alt="BLEU Score"></a>

<!-- METEOR Score -->
<a href="https://aclweb.org/anthology/W05-0909" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/METEOR_Score-555555?style=for-the-badge&logo=acl&logoColor=white" alt="METEOR Score"></a>

<!-- BERTScore -->
<a href="https://arxiv.org/abs/1904.09675" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/BERTScore-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="BERTScore"></a>

<!-- Human Evaluation: Engagement & Clarity -->
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0885230820300442" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Human_Evaluation-555555?style=for-the-badge&logo=sciencedirect&logoColor=white" alt="Human Evaluation"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Tools & Frameworks

<b>1] OpenAI Whisper</b> : A powerful, open-source speech-to-text model for accurate transcription.<br>
<b>2] SpeechT5</b> : A versatile model supporting both text-to-speech and speech-to-text tasks.<br>
<b>3] Coqui TTS</b> : An open-source framework for high-quality text-to-speech synthesis.<br>
<b>4] Mozilla DeepSpeech</b> : RNN-based speech recognition system inspired by Baidu’s Deep Speech research.<br>
<b>5] Rasa</b> : Open-source conversational AI platform combining NLP and machine learning for chatbots.<br>
<b>6] Google Gemini</b> : Multimodal large communication model integrating multiple data types for advanced AI.<br>
<b>7] Meta SeamlessM4T</b> : Multilingual, multimodal translation system supporting speech, text, and vision.<br>
<b>8] Azure Speech Service</b> : Cloud-based service offering speech recognition, synthesis, and translation APIs.<br>

<a href="https://openai.com/research/whisper" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_Whisper-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI Whisper"></a>

<a href="https://huggingface.co/microsoft/speecht5_tts" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/SpeechT5-555555?style=for-the-badge&logo=microsoft&logoColor=white" alt="SpeechT5"></a>

<a href="https://github.com/coqui-ai/TTS" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Coqui_TTS-555555?style=for-the-badge&logo=github&logoColor=white" alt="Coqui TTS"></a>

<a href="https://github.com/mozilla/DeepSpeech" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Mozilla_DeepSpeech-555555?style=for-the-badge&logo=mozilla&logoColor=white" alt="Mozilla DeepSpeech"></a>

<a href="https://rasa.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Rasa_AI-555555?style=for-the-badge&logo=rasa&logoColor=white" alt="Rasa"></a>

<a href="https://deepmind.google/technologies/gemini/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_Gemini-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini"></a>

<a href="https://ai.meta.com/blog/seamlessm4t/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Meta_SeamlessM4T-555555?style=for-the-badge&logo=meta&logoColor=white" alt="Meta SeamlessM4T"></a>

<a href="https://azure.microsoft.com/en-us/products/cognitive-services/speech-services" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Azure_Speech_Service-555555?style=for-the-badge&logo=microsoftazure&logoColor=white" alt="Azure Speech Service"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Official Resources
<a href="https://openai.com/research/whisper" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_Whisper-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI Whisper"></a>

<a href="https://ai.meta.com/blog/seamlessm4t/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Meta_SeamlessM4T-555555?style=for-the-badge&logo=meta&logoColor=white" alt="Meta SeamlessM4T"></a>

<a href="https://arxiv.org/abs/2110.07205" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/SpeechT5_Research-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="SpeechT5 Research Paper"></a>

<a href="https://rasa.com/docs/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Rasa_Documentation-555555?style=for-the-badge&logo=rasa&logoColor=white" alt="Rasa Documentation"></a>

<a href="https://deepmind.google/technologies/gemini/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_Gemini-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini"></a>

<a href="https://www.coursera.org/learn/natural-language-processing" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Coursera_NLP_Dialogue_Systems-555555?style=for-the-badge&logo=coursera&logoColor=white" alt="Coursera NLP & Dialogue Systems"></a>

<a href="https://www.coursera.org/specializations/natural-language-processing" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/DeepLearningAI_NLP_Specialization-555555?style=for-the-badge&logo=coursera&logoColor=white" alt="DeepLearning.AI NLP Specialization"></a>


<a href="https://huggingface.co/learn/nlp-course/chapter1" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Hugging_Face_NLP_Course-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face NLP Course"></a>

<a href="https://web.stanford.edu/class/cs25/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Stanford_CS25_Transformers-555555?style=for-the-badge&logo=stanford&logoColor=white" alt="Stanford CS25 Transformers Course"></a>

<a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/ChatGPT_Prompt_Engineering-555555?style=for-the-badge&logo=deeplearningai&logoColor=white" alt="ChatGPT Prompt Engineering"></a>

<a href="https://platform.openai.com/docs/tutorials" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_API_Documentation-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI API Documentation"></a>

<a href="https://www.coursera.org/learn/large-language-models" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Coursera_Large_Language_Models-555555?style=for-the-badge&logo=coursera&logoColor=white" alt="Coursera Large Language Models"></a>

<a href="https://www.udemy.com/course/large-language-models-and-transformers/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Udemy_LLMs_and_Transformers-555555?style=for-the-badge&logo=udemy&logoColor=white" alt="Udemy LLMs and Transformers"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### LCMs vs LLMs: What’s the Difference?

| Feature | LLMs (Large Language Models) | LCMs (Language & Communication Models) |
|--------|-------------------------------|----------------------------------------|
| Modality | Text-only | Text + Speech + Emotion + Multimodal |
| Focus | Text generation and understanding | Human-like communication and interaction |
| Applications | Chatbots, summarization, RAG | Voice assistants, translators, emotion-aware AI |
| Technologies | Transformers, RAG | Transformers + ASR + TTS + Fusion Models |



---

<div align="center">
   ⚠️ This repository is uniquely designed by @JoshuaThadi 
</div>



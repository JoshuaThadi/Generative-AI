<img width="100%" src="https://github.com/JoshuaThadi/Generative-AI/blob/main/assests/banner.png">

<div align="center">
<a href="https://github.com/JoshuaThadi/Generative-AI/blob/main/GenAI-roadmap.md">
  <img src="https://img.shields.io/badge/Generative_AI-roadmap-grey?style=for-the-badge&logo=markdown&logoColor=white" alt="GenAI Roadmap Badge"></a>

<a href="https://github.com/JoshuaThadi/Generative-AI/blob/main/LCMs-roadmap.md">
  <img src="https://img.shields.io/badge/LCMs-roadmap-grey?style=for-the-badge&logo=markdown&logoColor=white" alt="LCMs Roadmap Badge"></a>

<a href="https://github.com/JoshuaThadi/Generative-AI/blob/main/LLMs-roadmap.md">
  <img src="https://img.shields.io/badge/LLMs-roadmap-grey?style=for-the-badge&logo=markdown&logoColor=white" alt="LLMs Roadmap Badge"></a>
</div>


## ★ Generative AI
Generative AI refers to a class of artificial intelligence models designed to create new content such as text, images, audio, or video by learning patterns from existing data. These models, like GANs, VAEs, and Transformers, can generate realistic and creative outputs that mimic human-like creativity. Applications range from writing and art generation to code synthesis and music composition.


### Topics Covered in Generative AI

<b>1] Fundamentals of Generative AI</b> : Learn how AI models create new data like text, images, audio, and more from patterns in training data. <br>
<b>2] Text, Image, Audio, Video, and Code Generation</b> : Explore how AI systems generate content across multiple modalities using deep learning techniques. <br>
<b>3] GANs (Generative Adversarial Networks)</b> : Use two neural networks in competition to produce highly realistic synthetic data. <br>
<b>4] VAEs (Variational Autoencoders)</b> : Learn how VAEs encode data into a latent space and decode it for controlled and smooth data generation. <br>
<b>5] Diffusion Models</b> : Generate high-quality images by reversing a noise-based degradation process through iterative denoising. <br>
<b>6] Transformers</b> : Foundation of modern generative AI, leveraging self-attention for sequential data generation in models like GPT and BERT. <br>
<b>7] Deepfakes and Ethics</b> : Understand the ethical implications and risks of synthetic media that mimics real people or voices. <br>
<b>8] BLEU (Bilingual Evaluation Understudy)</b> : Measures n-gram overlap between generated and reference text, often used in machine translation. <br>
<b>9] ROUGE (Recall-Oriented Understudy for Gisting Evaluation)</b> : Evaluates the recall of overlapping phrases in generated summaries compared to references. <br>
<b>10] FID (Fréchet Inception Distance)</b> : Quantifies image quality by comparing the feature distribution of real and generated images. <br>
<b>11] Inception Score</b> : Evaluates image generation by assessing both object recognizability and output diversity. <br>
<b>12] Applications in Art, Music, Content, Code, Avatars</b> : Generative AI is driving innovation in creativity, enabling tools for art, music composition, coding, and virtual avatars. <br>



<!-- 2. Multimodal Generation -->
<a href="https://platform.openai.com/examples" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Text_Image_Audio_Video_Code_Generation-555555?style=for-the-badge&logo=OpenAI&logoColor=white" alt="Multimodal Generation"></a>

<!-- 3. GANs -->
<a href="https://www.ibm.com/think/topics/generative-adversarial-networks" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/GANs_(Generative_Adversarial_Networks)-555555?style=for-the-badge&logo=keras&logoColor=white" alt="GANs"></a>

<!-- 7. Deepfakes and Ethics -->
<a href="https://tepperspectives.cmu.edu/all-articles/deepfakes-and-the-ethics-of-generative-ai/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Deepfakes_&_Ethics-555555?style=for-the-badge&logo=datadog&logoColor=white" alt="Deepfakes and Ethics"></a>

<!-- 8.1 BLEU -->
<a href="https://en.wikipedia.org/wiki/BLEU" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/BLEU_Score-555555?style=for-the-badge&logo=wikidata&logoColor=white" alt="BLEU Score"></a>

<!-- 4. VAEs -->
<a href="https://www.ibm.com/think/topics/variational-autoencoder" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/VAEs_(Variational_Autoencoders)-555555?style=for-the-badge&logo=keras&logoColor=white" alt="VAEs"></a>


<!-- 8.3 FID -->
<a href="https://github.com/mseitzer/pytorch-fid" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/FID_(Fréchet_Inception_Distance)-555555?style=for-the-badge&logo=pytorch&logoColor=white" alt="FID"></a>

<!-- 6. Transformers -->
<a href="https://huggingface.co/transformers/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Transformers-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Transformers"></a>

<!-- 8.2 ROUGE -->
<a href="https://en.wikipedia.org/wiki/ROUGE_(metric)" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/ROUGE_Score-555555?style=for-the-badge&logo=wikidata&logoColor=white" alt="ROUGE Score"></a>

<!-- 1. Fundamentals of Generative AI -->
<a href="https://www.coursera.org/learn/generative-ai-introduction-and-applications?action=enroll&adgroupid=169459011518&assetgroupid=&campaignid=21794529004&creativeid=716372273447&device=c&devicemodel=&extensionid=&gad_campaignid=21794529004&gad_source=1&gbraid=0AAAAADdKX6bqFlLtMqZPdcVqmikhQqfzc&gclid=CjwKCAjwg7PDBhBxEiwAf1CVu52L2YVZwZ0iu73skO_cYIwzbrBU8iDhfpWhtPvyRWvvJYB9j4COgBoC98cQAvD_BwE&keyword=&matchtype=&network=g&placement=&targetid=dsa-2420290992847&utm_campaign=b2c_india_generative-ai-for-human-resources_ibm_ftcof_specializations_px_dr_bau_gg_sem_pr_in_all_m_hyb_24-10_x&utm_medium=sem&utm_source=gg" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Fundamentals_of_Generative_AI-555555?style=for-the-badge&logo=OpenAI&logoColor=white" alt="Fundamentals of Generative AI"></a>


<!-- 9. Applications -->
<a href="https://openai.com/sora" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Generative_AI_Applications-555555?style=for-the-badge&logo=artstation&logoColor=white" alt="Generative AI Applications"></a>

<!-- 5. Diffusion Models -->
<a href="https://huggingface.co/docs/diffusers/index" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Diffusion_Models-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Diffusion Models"></a>

<!-- 8.4 Inception Score -->
<a href="https://en.wikipedia.org/wiki/Inception_score" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Inception_Score-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="Inception Score"></a>


<div>
  <p>
    <h1></h1>
  </p>
</div>


### Tools & Frameworks for Generative AI

<b>1] Hugging Face Transformers</b> : A leading library for using and training state-of-the-art NLP and multimodal transformer models.<br>
<b>2] Diffusers</b> : A Hugging Face library for implementing diffusion models for high-quality image and media generation.<br>
<b>3] OpenAI API</b> : Provides access to GPT, DALL·E, Whisper, and other powerful foundation models via API.<br>
<b>4] Runway ML</b> : A no-code platform for creatives to use generative AI models in design, art, and video.<br>
<b>5] Gradio</b> : Simplifies ML model deployment by allowing developers to build interactive UIs in just a few lines of code.<br>
<b>6] Replicate</b> : Enables running and sharing ML models in the cloud without infrastructure setup.<br>
<b>7] TensorFlow</b> : An open-source deep learning framework for building and training scalable machine learning models.<br>
<b>8] PyTorch</b> : A flexible and developer-friendly deep learning library widely used for research and production.<br>


<!-- Replicate -->
<a href="https://replicate.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Replicate-555555?style=for-the-badge&logo=cloudflare&logoColor=white" alt="Replicate"></a>

<!-- TensorFlow -->
<a href="https://www.tensorflow.org/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/TensorFlow-555555?style=for-the-badge&logo=tensorflow&logoColor=white" alt="TensorFlow"></a>

<!-- Hugging Face Transformers -->
<a href="https://huggingface.co/transformers" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Hugging_Face_Transformers-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face Transformers"></a>

<!-- Diffusers -->
<a href="https://huggingface.co/docs/diffusers" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Diffusers-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Diffusers"></a>

<!-- OpenAI API -->
<a href="https://platform.openai.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_API-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI API"></a>

<!-- Runway ML -->
<a href="https://runwayml.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Runway_ML-555555?style=for-the-badge&logo=vercel&logoColor=white" alt="Runway ML"></a>

<!-- Gradio -->
<a href="https://gradio.app/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Gradio-555555?style=for-the-badge&logo=python&logoColor=white" alt="Gradio"></a>

<!-- PyTorch -->
<a href="https://pytorch.org/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/PyTorch-555555?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Official Resources for Generative AI


<!-- Coursera Deep Learning Specialization -->
<a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Coursera_Deep_Learning_Specialization-555555?style=for-the-badge&logo=coursera&logoColor=white" alt="Coursera Deep Learning Specialization"></a>

<!-- NVIDIA Deep Learning Institute -->
<a href="https://developer.nvidia.com/deep-learning-institute" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/NVIDIA_Deep_Learning_Institute-555555?style=for-the-badge&logo=nvidia&logoColor=white" alt="NVIDIA Deep Learning Institute"></a>

<!-- DeepLearning.AI - Generative AI with LLMs -->
<a href="https://www.coursera.org/learn/generative-ai-for-everyone?utm_medium=sem&utm_source=gg&utm_campaign=b2c_india_generative-ai-for-everyone_deeplearning-ai_ftcof_learn_cx_dr_bau_gg_sem_pr_in_all_m_hyb_25-05_x&campaignid=22610002514&adgroupid=183218873467&device=c&keyword=generative%20ai%20for%20everyone%20course&matchtype=p&network=g&devicemodel=&creativeid=754898884707&assetgroupid=&targetid=kwd-2418803344930&extensionid=&placement=&gad_source=1&gad_campaignid=22610002514&gbraid=0AAAAADdKX6YdI7TEN9bkOjTn22G9Rv5yJ&gclid=CjwKCAjwg7PDBhBxEiwAf1CVu20ckoghHIIJo3xbnrjc_jfADemRTaxt1l-ojrXO6gF1lt1XsP5T6RoCGo8QAvD_BwE" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/DeepLearning.AI_Generative_AI-555555?style=for-the-badge&logo=deeplearningai&logoColor=white" alt="DeepLearning.AI Generative AI"></a>


<!-- Fast.ai - Practical Deep Learning for Coders -->
<a href="https://course.fast.ai/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Fast.ai_Deep_Learning-555555?style=for-the-badge&logo=fastapi&logoColor=white" alt="Fast.ai Deep Learning"></a>

<!-- Hugging Face Course - Diffusers and Transformers -->
<a href="https://huggingface.co/course/chapter7" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/HuggingFace_Course-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face Course"></a>

<!-- OpenAI API Documentation -->
<a href="https://platform.openai.com/docs" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_API_Docs-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI API Docs"></a>

<!-- Google AI Courses -->
<a href="https://ai.google/education/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_AI_Education-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google AI Education"></a>

<!-- Udemy Machine Learning Courses -->
<a href="https://www.udemy.com/topic/machine-learning/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Udemy_Machine_Learning-555555?style=for-the-badge&logo=udemy&logoColor=white" alt="Udemy Machine Learning"></a>

<!-- Coursera Machine Learning by Andrew Ng -->
<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Coursera_Andrew_Ng_ML-555555?style=for-the-badge&logo=coursera&logoColor=white" alt="Coursera Andrew Ng ML"></a>

<!-- MIT Deep Learning Lectures -->
<a href="https://introtodeeplearning.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/MIT_Deep_Learning-555555?style=for-the-badge&logo=mit&logoColor=white" alt="MIT Deep Learning Lectures"></a>

  

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Technologies used in Generative AI
<a href="https://pytorch.org/">
  <img src="https://img.shields.io/badge/PyTorch-E34C26?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch"></a>
<a href="https://www.tensorflow.org/">
  <img src="https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" alt="TensorFlow"></a>
<a href="https://huggingface.co/">
  <img src="https://img.shields.io/badge/HuggingFace-FFD21F?style=for-the-badge&logo=huggingface&logoColor=black" alt="Hugging Face"></a>
<a href="https://platform.openai.com/">
  <img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI"></a>
<a href="https://www.stability.ai/">
  <img src="https://img.shields.io/badge/StableDiffusion-16A085?style=for-the-badge&logo=stable%20diffusion&logoColor=white" alt="Stable Diffusion"></a>
<a href="https://github.com/huggingface/diffusers">
  <img src="https://img.shields.io/badge/Diffusers-FFC107?style=for-the-badge&logo=python&logoColor=black" alt="Diffusers"></a>


---

<br>
<br>

## ☆ Large Language Models (LLMs)
Large Language Models (LLMs) are advanced AI models trained on vast amounts of text data to understand and generate human-like language. They use architectures like Transformers to predict and produce coherent text, enabling tasks such as translation, summarization, question-answering, and conversation. Examples include GPT, LLaMA, and PaLM. LLMs power many modern natural language applications and conversational AI systems.


<div>
  <p>
    <h1></h1>
  </p>
</div>

### Topics Covered in LLMs

<b>1] Transformer Architecture & Self-Attention</b> : Core deep learning model using attention to process sequences efficiently and capture context.<br>
<b>2] Pretraining & Fine-tuning (LoRA, PEFT, RLHF)</b> : Techniques to adapt large models for specific tasks by efficient training and reinforcement learning.<br>
<b>3] Prompt Engineering (Zero-shot, Few-shot, CoT)</b> : Designing effective input prompts to guide language models’ responses without extensive retraining.<br>
<b>4] Evaluation Metrics (Perplexity, LAMBADA, TruthfulQA)</b> : Quantitative measures to assess language model performance and truthfulness on complex tasks.<br>
<b>5] Model Deployment, Scalability, and Cost Estimation</b> : Strategies to efficiently serve models at scale while managing computational resources and expenses.<br>
<b>6] RAG (Retrieval Augmented Generation)</b> : Combining retrieval systems with generative models to improve answer accuracy using external knowledge.<br>
<b>7] Ethics: Hallucination, Security, Jailbreaking</b> : Addressing risks of misinformation, system vulnerabilities, and adversarial exploitation in AI models.<br>


<!-- Model Deployment, Scalability, and Cost Estimation -->
<a href="https://docs.truefoundry.com/docs/deploying-an-llm-model-from-the-model-catalogue" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Model_Deployment-555555?style=for-the-badge&logo=tensorflow&logoColor=white" alt="Model Deployment"></a>

<!-- Ethics: Hallucination, Security, Jailbreaking -->
<a href="https://ai.google/responsibilities/responsible-ai-practices/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Ethics_in_AI-555555?style=for-the-badge&logo=google&logoColor=white" alt="AI Ethics"></a>

<!-- RAG (Retrieval Augmented Generation) -->
<a href="https://aws.amazon.com/what-is/retrieval-augmented-generation/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/RAG_Retrieval_Augmented_Generation-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="RAG"></a>

<!-- Pretraining & Fine-tuning (LoRA, PEFT, RLHF) -->
<a href="https://huggingface.co/blog/peft" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Pretraining_&_Fine-tuning-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Pretraining and Fine-tuning"></a>


<!-- Transformer Architecture & Self-Attention -->
<a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Transformer_Architecture-555555?style=for-the-badge&logo=visualstudiocode&logoColor=white" alt="Transformer Architecture"></a>

<!-- Prompt Engineering (Zero-shot, Few-shot, CoT) -->
<a href="https://cloud.google.com/discover/what-is-prompt-engineering?hl=en" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Prompt_Engineering-555555?style=for-the-badge&logo=microsoftazure&logoColor=white" alt="Prompt Engineering"></a>

<!-- Evaluation Metrics (Perplexity, LAMBADA, TruthfulQA) -->
<a href="https://www.confident-ai.com/blog/llm-evaluation-metrics-everything-you-need-for-llm-evaluation" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Evaluation_Metrics-555555?style=for-the-badge&logo=researchgate&logoColor=white" alt="Evaluation Metrics"></a>


<div>
  <p>
    <h1></h1>
  </p>
</div>

### Tools & Frameworks for LLMs

<b>1] Hugging Face Models</b> : Offers thousands of open-source pre-trained models for NLP, vision, audio, and more.<br>
<b>2] LangChain</b> : A framework to build LLM-powered apps by chaining prompts, tools, and memory together.<br>
<b>3] OpenAI GPT-3.5/4</b> : Leading proprietary large language models with world-class reasoning and generation capabilities.<br>
<b>4] Meta LLaMA 2 / 3</b> : Open-weight transformer models built by Meta for research and commercial use.<br>
<b>5] Claude (Anthropic)</b> : Constitutional AI-based LLM with strong reasoning, harmlessness, and helpfulness principles.<br>
<b>6] Google Gemini</b> : Multimodal foundation model from DeepMind capable of text, vision, and code understanding.<br>
<b>7] Mistral AI</b> : Efficient, high-performance open-weight LLMs optimized for real-world deployment.<br>
<b>8] Haystack</b> : Powerful framework for building retrieval-augmented generation (RAG) pipelines using LLMs.<br>


<!-- Google Gemini -->
<a href="https://deepmind.google/technologies/gemini/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_Gemini-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini"></a>

<!-- Mistral AI -->
<a href="https://mistral.ai/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Mistral_AI-555555?style=for-the-badge&logo=airbnb&logoColor=white" alt="Mistral AI"></a>

<!-- Haystack -->
<a href="https://haystack.deepset.ai/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Haystack_RAG_Framework-555555?style=for-the-badge&logo=elasticstack&logoColor=white" alt="Haystack"></a>

<!-- Hugging Face Models -->
<a href="https://huggingface.co/models" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Hugging_Face_Models-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face Models"></a>

<!-- LangChain -->
<a href="https://www.langchain.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/LangChain_Framework-555555?style=for-the-badge&logo=chainlink&logoColor=white" alt="LangChain"></a>

<!-- OpenAI GPT-3.5/4 -->
<a href="https://platform.openai.com/docs" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_GPT_3.5/4-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI GPT"></a>

<!-- Meta LLaMA 2 / 3 -->
<a href="https://ai.meta.com/llama/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Meta_LLaMA_2/3-555555?style=for-the-badge&logo=meta&logoColor=white" alt="Meta LLaMA"></a>

<!-- Claude (Anthropic) -->
<a href="https://www.anthropic.com/index/claude" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Claude_(Anthropic)-555555?style=for-the-badge&logo=anthropic&logoColor=white" alt="Claude"></a>


<div>
  <p>
    <h1></h1>
  </p>
</div>

### Official Resources for LLMs

<!-- Hugging Face NLP Course -->
<a href="https://huggingface.co/learn/nlp-course/chapter1" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/HuggingFace_NLP_Course-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face NLP Course"></a>

<!-- Stanford CS25 Transformers Course -->
<a href="https://web.stanford.edu/class/cs25/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Stanford_CS25_Transformers-555555?style=for-the-badge&logo=academia&logoColor=white" alt="Stanford CS25 Transformers"></a>

<!-- Andrej Karpathy – Neural Networks Zero to Hero -->
<a href="https://www.youtube.com/playlist?list=PLpzmRsG7u_gta8p3WGuUq4I1R9apS8Wlg" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Karpathy_Zero_to_Hero-555555?style=for-the-badge&logo=youtube&logoColor=white" alt="Karpathy Zero to Hero"></a>

<!-- OpenAI Cookbook -->
<a href="https://github.com/openai/openai-cookbook" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_Cookbook-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI Cookbook"></a>

<!-- LangChain Documentation -->
<a href="https://docs.langchain.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/LangChain_Docs-555555?style=for-the-badge&logo=chainlink&logoColor=white" alt="LangChain Documentation"></a>

<!-- Anthropic Claude API Docs -->
<a href="https://docs.anthropic.com/claude" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Claude_API_Docs-555555?style=for-the-badge&logo=anthropic&logoColor=white" alt="Claude API Docs"></a>



<div>
  <p>
    <h1></h1>
  </p>
</div>

### Technologies used in LLMs
<a href="https://huggingface.co/transformers/">
  <img src="https://img.shields.io/badge/Transformers-FCC624?style=for-the-badge&logo=python&logoColor=black" alt="Transformers"></a>
<a href="https://langchain.com/">
  <img src="https://img.shields.io/badge/LangChain-00B86B?style=for-the-badge&logo=chainlink&logoColor=white" alt="LangChain"></a>
<a href="https://www.llamaindex.ai/">
  <img src="https://img.shields.io/badge/LlamaIndex-009688?style=for-the-badge&logo=llama&logoColor=white" alt="LlamaIndex"></a>
<a href="https://platform.openai.com/docs">
  <img src="https://img.shields.io/badge/OpenAI%20API-000000?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI API"></a>
<a href="https://www.anthropic.com/index/claude">
  <img src="https://img.shields.io/badge/Claude-2C2C2C?style=for-the-badge&logoColor=white" alt="Claude by Anthropic"></a>
<a href="https://deepmind.google/technologies/gemini/">
  <img src="https://img.shields.io/badge/Gemini-4285F4?style=for-the-badge&logo=google&logoColor=white" alt="Gemini"></a>
<a href="https://mistral.ai/">
  <img src="https://img.shields.io/badge/Mistral-A2D2FF?style=for-the-badge&logo=cloudflare&logoColor=black" alt="Mistral"></a>


---

<br>
<br>

## ✪ Language and Communication Models 
Language and Communication Models are AI systems that extend beyond text understanding to include human communication aspects like speech, emotion, and multimodal inputs (e.g., audio, video, and text). They power technologies such as speech recognition, text-to-speech, conversational agents, and emotion-aware AI, enabling more natural and context-aware interactions between humans and machines.


<div>
  <p>
    <h1></h1>
  </p>
</div>

### Core Concepts – Foundations of Human-AI Communication

<b>1] Language vs. Communication Models</b> : Understanding the distinction between structured language models and broader human communication patterns.<br>
<b>2] Speech, Text, and Emotion as Modalities</b> : Key modalities processed by AI to understand and generate human-like interactions.<br>
<b>3] Pragmatics, Semantics, and Context-awareness</b> : How AI interprets meaning, tone, and context beyond literal text.<br>


<!-- Pragmatics, Semantics, and Context-awareness -->
<a href="https://plato.stanford.edu/entries/pragmatics/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Pragmatics_Semantics_Context-555555?style=for-the-badge&logo=stanford&logoColor=white" alt="Pragmatics, Semantics, Context-awareness"></a>

<!-- Language vs. Communication Models -->
<a href="https://en.wikipedia.org/wiki/Language_model" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Language_vs_Communication-555555?style=for-the-badge&logo=wikipedia&logoColor=white" alt="Language vs Communication Models"></a>

<!-- Speech, Text, and Emotion as Modalities -->
<a href="https://www.sciencedirect.com/science/article/pii/S2667305324001108" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Speech_Text_Emotion-555555?style=for-the-badge&logo=sciencedirect&logoColor=white" alt="Speech, Text, and Emotion Modalities"></a>


<div>
  <p>
    <h1></h1>
  </p>
</div>

### Communication Systems – Speech, Dialogue & Emotion Interfaces

<b>1] Conversational AI & Dialogue Systems</b> : AI agents designed to engage in meaningful, coherent conversations with users.<br>
<b>2] Speech-to-Text (ASR)</b> : Converts spoken audio into textual data for analysis and response.<br>
<b>3] Text-to-Speech (TTS)</b> : Converts written text into natural-sounding human speech.<br>
<b>4] Emotion & Sentiment Recognition</b> : Detects affective states in voice or text to tailor responses.<br>
<b>5] Multimodal Language Understanding</b> : Combines input like video, audio, and text to enable richer AI understanding.<br>


<!-- Multimodal Language Understanding -->
<a href="https://www.moveworks.com/us/en/resources/ai-terms-glossary/multimodal-language-models0" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Multimodal_Language_Understanding-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="Multimodal Language Understanding"></a>

<!-- Conversational AI & Dialogue Systems -->
<a href="https://www.ibm.com/think/topics/conversational-ai" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Conversational_AI-555555?style=for-the-badge&logo=google&logoColor=white" alt="Conversational AI & Dialogue Systems"></a>

<!-- Speech-to-Text (ASR) -->
<a href="https://en.wikipedia.org/wiki/Speech_synthesis" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Speech_to_Text_ASR-555555?style=for-the-badge&logo=google&logoColor=white" alt="Speech-to-Text ASR"></a>

<!-- Text-to-Speech (TTS) -->
<a href="https://simple.wikipedia.org/wiki/Text_to_speech" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Text_to_Speech_TTS-555555?style=for-the-badge&logo=google&logoColor=white" alt="Text-to-Speech TTS"></a>

<!-- Emotion & Sentiment Recognition -->
<a href="https://viso.ai/deep-learning/visual-emotion-ai-recognition/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Emotion_Sentiment_AI-555555?style=for-the-badge&logo=affectiva&logoColor=white" alt="Emotion & Sentiment Recognition"></a>


<div>
  <p>
    <h1></h1>
  </p>
</div>

### Architectures and Techniques – State-of-the-art AI for Audio & Multimodal Tasks

<b>1] Transformer-based speech models</b> : Models using self-attention to process audio sequences effectively.<br>
<b>2] Audio Transformers (Whisper, SpeechT5)</b> : Advanced models designed for speech recognition, translation, and synthesis.<br>
<b>3] Multimodal Fusion (Gemini, GPT-4o, SeamlessM4T)</b> : Combines modalities (audio, visual, text) in a single unified model.<br>
<b>4] Reinforcement Learning for Dialog Control</b> : Uses reward mechanisms to optimize interactive conversations.<br>
<b>5] Attention-based ASR/TTS systems</b> : Employs attention mechanisms for accurate speech recognition and synthesis.<br>


<!-- Reinforcement Learning for Dialog Control -->
<a href="https://paperswithcode.com/paper/deep-reinforcement-learning-for-dialogue" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Reinforcement_Learning_Dialog-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="RL for Dialog Control"></a>

<!-- Transformer-based speech models -->
<a href="https://huggingface.co/learn/audio-course/en/chapter3/introduction" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Transformer_Speech_Models-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="Transformer-based Speech Models"></a>

<!-- Audio Transformers (Whisper, SpeechT5) -->
<a href="https://github.com/openai/whisper" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_Whisper-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI Whisper"></a>
<a href="https://huggingface.co/microsoft/speecht5_tts" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/SpeechT5_(HuggingFace)-555555?style=for-the-badge&logo=microsoft&logoColor=white" alt="SpeechT5"></a>

<!-- Multimodal Fusion (Gemini, GPT-4o, SeamlessM4T) -->
<a href="https://deepmind.google/technologies/gemini/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_Gemini-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini"></a>
<a href="https://ai.meta.com/research/publications/seamless-m4t/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Meta_SeamlessM4T-555555?style=for-the-badge&logo=meta&logoColor=white" alt="SeamlessM4T"></a>

<!-- Attention-based ASR/TTS systems -->
<a href="https://arxiv.org/abs/1506.07503" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Attention_ASR_TTS-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="Attention-based ASR/TTS"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Evaluation – How We Measure Communication AI

<b>1] Naturalness and Fluency of Speech</b> : Evaluates how human-like and fluid the generated speech sounds.<br>
<b>2] Emotion Detection Accuracy</b> : Measures how well the model captures human emotional states.<br>
<b>3] BLEU, METEOR, BERTScore</b> : Text-level evaluation metrics for measuring generated vs. reference quality.<br>
<b>4] Human Evaluation: Engagement & Clarity</b> : Real-user feedback to judge interaction quality and coherence.<br>

<!-- Naturalness and Fluency of Speech -->
<a href="https://www.sciencedirect.com/science/article/abs/pii/S0094730X08000521" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Naturalness_and_Fluency-555555?style=for-the-badge&logo=ieee&logoColor=white" alt="Naturalness and Fluency of Speech"></a>

<!-- Emotion Detection Accuracy -->
<a href="https://www.sciencedirect.com/science/article/abs/pii/S1568494625001784" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Emotion_Detection_Accuracy-555555?style=for-the-badge&logo=ieee&logoColor=white" alt="Emotion Detection Accuracy"></a>

<!-- BLEU Score -->
<a href="https://en.wikipedia.org/wiki/BLEU" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/BLEU_Score-555555?style=for-the-badge&logo=acl&logoColor=white" alt="BLEU Score"></a>

<!-- METEOR Score -->
<a href="https://en.wikipedia.org/wiki/METEOR" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/METEOR_Score-555555?style=for-the-badge&logo=acl&logoColor=white" alt="METEOR Score"></a>

<!-- BERTScore -->
<a href="https://huggingface.co/spaces/evaluate-metric/bertscore" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/BERTScore-555555?style=for-the-badge&logo=arxiv&logoColor=white" alt="BERTScore"></a>

<!-- Human Evaluation: Engagement & Clarity -->
<a href="https://www.sciencedirect.com/science/article/pii/S088523082030084X" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Human_Evaluation-555555?style=for-the-badge&logo=sciencedirect&logoColor=white" alt="Human Evaluation"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Tools & Frameworks

<b>1] OpenAI Whisper</b> : A powerful, open-source speech-to-text model for accurate transcription.<br>
<b>2] SpeechT5</b> : A versatile model supporting both text-to-speech and speech-to-text tasks.<br>
<b>3] Coqui TTS</b> : An open-source framework for high-quality text-to-speech synthesis.<br>
<b>4] Mozilla DeepSpeech</b> : RNN-based speech recognition system inspired by Baidu’s Deep Speech research.<br>
<b>5] Rasa</b> : Open-source conversational AI platform combining NLP and machine learning for chatbots.<br>
<b>6] Google Gemini</b> : Multimodal large communication model integrating multiple data types for advanced AI.<br>
<b>7] Meta SeamlessM4T</b> : Multilingual, multimodal translation system supporting speech, text, and vision.<br>
<b>8] Azure Speech Service</b> : Cloud-based service offering speech recognition, synthesis, and translation APIs.<br>

<a href="https://openai.com/research/whisper" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_Whisper-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI Whisper"></a>

<a href="https://huggingface.co/microsoft/speecht5_tts" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/SpeechT5-555555?style=for-the-badge&logo=microsoft&logoColor=white" alt="SpeechT5"></a>

<a href="https://github.com/coqui-ai/TTS" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Coqui_TTS-555555?style=for-the-badge&logo=github&logoColor=white" alt="Coqui TTS"></a>

<a href="https://github.com/mozilla/DeepSpeech" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Mozilla_DeepSpeech-555555?style=for-the-badge&logo=mozilla&logoColor=white" alt="Mozilla DeepSpeech"></a>

<a href="https://rasa.com/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Rasa_AI-555555?style=for-the-badge&logo=rasa&logoColor=white" alt="Rasa"></a>

<a href="https://deepmind.google/technologies/gemini/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Google_Gemini-555555?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini"></a>

<a href="https://ai.meta.com/blog/seamlessm4t/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Meta_SeamlessM4T-555555?style=for-the-badge&logo=meta&logoColor=white" alt="Meta SeamlessM4T"></a>

<a href="https://azure.microsoft.com/en-us/products/cognitive-services/speech-services" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Azure_Speech_Service-555555?style=for-the-badge&logo=microsoftazure&logoColor=white" alt="Azure Speech Service"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Official Resources

<a href="https://rasa.com/docs/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Rasa_Documentation-555555?style=for-the-badge&logo=rasa&logoColor=white" alt="Rasa Documentation"></a>


<a href="https://www.coursera.org/specializations/natural-language-processing" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/DeepLearningAI_NLP_Specialization-555555?style=for-the-badge&logo=coursera&logoColor=white" alt="DeepLearning.AI NLP Specialization"></a>

<a href="https://huggingface.co/learn/nlp-course/chapter1" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Hugging_Face_NLP_Course-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Hugging Face NLP Course"></a>

<a href="https://web.stanford.edu/class/cs25/" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Stanford_CS25_Transformers-555555?style=for-the-badge&logo=stanford&logoColor=white" alt="Stanford CS25 Transformers Course"></a>

<a href="https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/ChatGPT_Prompt_Engineering-555555?style=for-the-badge&logo=deeplearningai&logoColor=white" alt="ChatGPT Prompt Engineering"></a>

<a href="https://platform.openai.com/docs/tutorials" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/OpenAI_API_Documentation-555555?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI API Documentation"></a>

<a href="https://www.coursera.org/learn/generative-ai-with-llms?utm_medium=sem&utm_source=gg&utm_campaign=b2c_india_generative-ai-with-llms_deeplearning-ai_ftcof_learn_cx_dr_bau_gg_sem_pr_in_all_m_hyb_24-05_x&campaignid=21241362459&adgroupid=158619676981&device=c&keyword=generative%20ai%20llm%20coursera&matchtype=p&network=g&devicemodel=&creativeid=698150770448&assetgroupid=&targetid=kwd-2225523835654&extensionid=&placement=&gad_source=1&gad_campaignid=21241362459&gbraid=0AAAAADdKX6ZwSXgDW41wanIjqKUEwLz9O&gclid=CjwKCAjwg7PDBhBxEiwAf1CVu6tyGx0o_eW4L1An7Bl16-XoVsiOGBanx3eG3PerYNencvAvunYD8RoCnJkQAvD_BwE" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Coursera_Large_Language_Models-555555?style=for-the-badge&logo=coursera&logoColor=white" alt="Coursera Large Language Models"></a>

<a href="https://www.udemy.com/course/mastering-ai-with-transformers-and-llms/?srsltid=AfmBOorDFtTJ6vmdqYBZN_OEB3DEvyoMR0xDVC8POxR0G4UEnwMmVR9d&couponCode=ST17MT70725G1" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Udemy_LLMs_and_Transformers-555555?style=for-the-badge&logo=udemy&logoColor=white" alt="Udemy LLMs and Transformers"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Technologies used

<a href="https://openai.com/research/whisper">
  <img src="https://img.shields.io/badge/Whisper-007ACC?style=for-the-badge&logo=waveform&logoColor=white" alt="OpenAI Whisper"></a>
<a href="https://huggingface.co/microsoft/speecht5_tts">
  <img src="https://img.shields.io/badge/SpeechT5-00ADEF?style=for-the-badge&logo=microsoft&logoColor=white" alt="SpeechT5"></a>
<a href="https://github.com/coqui-ai/TTS">
  <img src="https://img.shields.io/badge/Coqui_TTS-FFC107?style=for-the-badge&logo=googlevoice&logoColor=black" alt="Coqui TTS"></a>
<a href="https://rasa.com/">
  <img src="https://img.shields.io/badge/Rasa-A9225C?style=for-the-badge&logo=rasa&logoColor=white" alt="Rasa"></a>
<a href="https://ai.meta.com/blog/seamlessm4t/">
  <img src="https://img.shields.io/badge/SeamlessM4T-1877F2?style=for-the-badge&logo=meta&logoColor=white" alt="Meta SeamlessM4T"></a>
<a href="https://deepmind.google/technologies/gemini/">
  <img src="https://img.shields.io/badge/Gemini-34A853?style=for-the-badge&logo=google&logoColor=white" alt="Google Gemini"></a>
<a href="https://azure.microsoft.com/en-us/products/cognitive-services/speech-services">
  <img src="https://img.shields.io/badge/Azure_Speech-0078D4?style=for-the-badge&logo=microsoftazure&logoColor=white" alt="Azure Speech Services"></a>



<div>
  <p>
    <h1></h1>
  </p>
</div>

### What’s the Difference?

| Feature | Large Language Models | Language & Communication Models |
|--------|-------------------------------|----------------------------------------|
| Modality | Text-only | Text + Speech + Emotion + Multimodal |
| Focus | Text generation and understanding | Human-like communication and interaction |
| Applications | Chatbots, summarization, RAG | Voice assistants, translators, emotion-aware AI |
| Technologies | Transformers, RAG | Transformers + ASR + TTS + Fusion Models |


---

<br>
<br>

## ☆ Large Concept Models (LCMs)
Large Concept Models (LCMs) are generalist AI systems trained on multimodal and multi-domain data to learn abstract concepts, reason across modalities, and perform cross-task generalization. These models go beyond language, integrating text, audio, vision, and code into a unified conceptual framework. Examples include GPT-4o, Gemini, Claude, and SeamlessM4T.

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Topics Covered in LCMs

<b>1] Concept Learning & Abstraction</b> : Understanding symbolic reasoning, world knowledge, and abstract concept mapping across domains.<br>
<b>2] Multimodal Input/Output Fusion</b> : Integrating text, image, audio, and video using cross-attention and shared embeddings.<br>
<b>3] Generalist Intelligence & Tool Use</b> : Designing systems that perform multi-domain tasks with reasoning, planning, and memory.<br>
<b>4] Multimodal Architectures (MoE, Flamingo, Gemini, GPT-4o)</b> : Vision-language-audio models using expert routing and joint representations.<br>
<b>5] Constitutional & Ethical Reasoning</b> : Human-aligned learning with ethical filters and safety policies (e.g., Claude, Gemini).<br>
<b>6] Evaluation Benchmarks (MMMU, VQAv2, MMLU, TDI-Eval)</b> : Testing reasoning, factuality, and cross-modal comprehension.<br>
<b>7] Cross-Modal Dialogue & Emotion Understanding</b> : Coherent, emotionally aware responses across speech, text, and images.<br>

<!-- Concept Learning -->
<a href="https://www.datacamp.com/blog/large-concept-models" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Concept_Learning-555555?style=for-the-badge&logo=google&logoColor=white" alt="Concept Learning"></a>

<!-- Multimodal Fusion -->
<a href="https://www.educative.io/answers/what-is-multimodal-fusion" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Multimodal_Fusion-555555?style=for-the-badge&logo=meta&logoColor=white" alt="Multimodal Fusion"></a>

<!-- Generalist Intelligence -->
<a href="https://www.paltron.com/insights-en/specialisation-in-the-field-of-artificial-intelligence---generalist-vs-specialist" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Generalist_AI-555555?style=for-the-badge&logo=openai&logoColor=white" alt="Generalist Intelligence"></a>

<!-- Evaluation -->
<a href="https://huggingface.co/papers?filter=benchmark" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Evaluation_Benchmarks-555555?style=for-the-badge&logo=academia&logoColor=white" alt="Evaluation"></a>

<!-- Constitutional AI -->
<a href="https://www.nightfall.ai/ai-security-101/constitutional-ai" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/Constitutional_AI-555555?style=for-the-badge&logo=anthropic&logoColor=white" alt="Constitutional AI"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>

### Tools & Frameworks for LCMs

<b>1] GPT-4o (OpenAI)</b> : Multimodal unified model handling text, vision, and speech in real time.<br>
<b>2] Gemini (Google DeepMind)</b> : Conceptual agent with tool use, reasoning, and multimodal interaction.<br>
<b>3] Claude (Anthropic)</b> : Constitutional model with safety alignment and cross-modal grounding.<br>
<b>4] Meta SeamlessM4T</b> : Speech-to-speech translation with multilingual and multimodal fusion.<br>
<b>5] Flamingo</b> : Few-shot vision-language model from DeepMind.<br>
<b>6] LLaVA</b> : Visual-Language Assistant (open-source) for VL tasks.<br>
<b>7] Hugging Face Transformers</b> : Library for loading and fine-tuning foundational and multimodal models.<br>
<b>8] LangChain + LlamaIndex</b> : Used for orchestration and RAG-style workflows with LCMs.<br>

<!-- GPT-4o -->
<a href="https://openai.com/index/gpt-4o" target="_blank">
  <img src="https://img.shields.io/badge/OpenAI_GPT_4o-555555?style=for-the-badge&logo=openai&logoColor=white" alt="GPT-4o"></a>

<!-- Gemini -->
<a href="https://deepmind.google/technologies/gemini/" target="_blank">
  <img src="https://img.shields.io/badge/Google_Gemini-555555?style=for-the-badge&logo=google&logoColor=white" alt="Gemini"></a>

<!-- Claude -->
<a href="https://www.anthropic.com/index/claude" target="_blank">
  <img src="https://img.shields.io/badge/Claude_Anthropic-555555?style=for-the-badge&logo=anthropic&logoColor=white" alt="Claude"></a>

<!-- SeamlessM4T -->
<a href="https://ai.meta.com/blog/seamlessm4t/" target="_blank">
  <img src="https://img.shields.io/badge/Meta_SeamlessM4T-555555?style=for-the-badge&logo=meta&logoColor=white" alt="SeamlessM4T"></a>

<!-- Flamingo -->
<a href="https://www.deepmind.com/publications/flamingo-a-visual-language-model-for-few-shot-learning" target="_blank">
  <img src="https://img.shields.io/badge/Flamingo_DeepMind-555555?style=for-the-badge&logo=deepmind&logoColor=white" alt="Flamingo"></a>

<!-- LLaVA -->
<a href="https://llava-vl.github.io/" target="_blank">
  <img src="https://img.shields.io/badge/LLaVA-555555?style=for-the-badge&logo=github&logoColor=white" alt="LLaVA"></a>

<!-- Hugging Face Transformers -->
<a href="https://huggingface.co/docs/transformers/index" target="_blank">
  <img src="https://img.shields.io/badge/Hugging_Face_Transformers-555555?style=for-the-badge&logo=huggingface&logoColor=white" alt="Transformers"></a>

<!-- LangChain -->
<a href="https://www.langchain.com/" target="_blank">
  <img src="https://img.shields.io/badge/LangChain_Framework-555555?style=for-the-badge&logo=chainlink&logoColor=white" alt="LangChain"></a>

<!-- LlamaIndex -->
<a href="https://www.llamaindex.ai/" target="_blank">
  <img src="https://img.shields.io/badge/LlamaIndex-555555?style=for-the-badge&logo=llama&logoColor=white" alt="LlamaIndex"></a>

<div>
  <p>
    <h1></h1>
  </p>
</div>


### Advanced projects for Gen AI, LLMs and LCMs

<a href="https://github.com/JoshuaThadi/Generative-AI/blob/main/Projects.md" target="_blank" rel="noopener noreferrer">
  <img src="https://img.shields.io/badge/GenAI_LLMs_LCMs-Projects-555555?style=for-the-badge&logo=markdown&logoColor=white" alt="Generative AI Projects">
</a>



---

<div align="center">
   ⚠️ This repository is uniquely designed by @JoshuaThadi 
</div>





## 🔮 Generative AI

### Topics Covered in Generative AI

- Fundamentals of Generative AI
- Text, Image, Audio, Video, and Code generation
- GANs, VAEs, Diffusion models, and Transformers
- Deepfakes and Ethics
- Evaluation Metrics: BLEU, ROUGE, FID, Inception Score
- Applications in Art, Music, Content, Code, Avatars

### Tools & Frameworks for Generative AI

| Tool | Description | Link |
|------|-------------|------|
| Hugging Face Transformers | Pretrained models and training | [🔗](https://huggingface.co/transformers) |
| Diffusers | Diffusion-based image generation | [🔗](https://huggingface.co/docs/diffusers) |
| OpenAI API | GPT, DALL·E, Whisper, ChatGPT | [🔗](https://platform.openai.com/) |
| Runway ML | No-code generative design | [🔗](https://runwayml.com/) |
| Gradio | Deploy ML models in minutes | [🔗](https://gradio.app/) |
| Replicate | Run ML models in the cloud | [🔗](https://replicate.com/) |
| TensorFlow, PyTorch | Model building & training | [TensorFlow](https://www.tensorflow.org/) / [PyTorch](https://pytorch.org/) |

### Official Resources for Generative AI

- [🔗 DeepLearning.AI – Generative AI Courses](https://www.deeplearning.ai/courses/generative-ai/)
- [🔗 Google Cloud Generative AI Training](https://cloud.google.com/training/generative-ai)
- [🔗 Stability AI](https://stability.ai/)
- [🔗 OpenAI Research](https://openai.com/research)
- [🔗 Awesome Generative AI GitHub](https://github.com/steven2358/awesome-generative-ai)

---

## 🧠 Large Language Models (LLMs)

### Topics Covered in LLMs

- Transformer Architecture & Self-Attention
- Pretraining & Fine-tuning (LoRA, PEFT, RLHF)
- Prompt Engineering (Zero-shot, Few-shot, CoT)
- Evaluation Metrics (Perplexity, LAMBADA, TruthfulQA)
- Model deployment, scalability, and cost estimation
- RAG (Retrieval Augmented Generation)
- Ethics: Hallucination, Security, Jailbreaking

### Tools & Frameworks for LLMs

| Tool | Description | Link |
|------|-------------|------|
| Hugging Face Models | Thousands of pre-trained LLMs | [🔗](https://huggingface.co/models) |
| LangChain | LLM orchestration framework | [🔗](https://www.langchain.com/) |
| OpenAI GPT-3.5/4 | Industry-leading LLMs | [🔗](https://platform.openai.com/docs) |
| Meta LLaMA 2 / 3 | Open-weight transformer models | [🔗](https://ai.meta.com/llama/) |
| Claude (Anthropic) | Constitutional AI-based LLM | [🔗](https://www.anthropic.com/index/claude) |
| Google Gemini | Multimodal large model | [🔗](https://deepmind.google/technologies/gemini/) |
| Mistral AI | Open-weight LLMs | [🔗](https://mistral.ai/) |
| Haystack | Retrieval-Augmented Generation | [🔗](https://haystack.deepset.ai/) |

### Official Resources for LLMs

- [🔗 Hugging Face NLP Course](https://huggingface.co/learn/nlp-course/chapter1)
- [🔗 Stanford CS25 Transformers Course](https://web.stanford.edu/class/cs25/)
- [🔗 Andrej Karpathy – Neural Networks Zero to Hero](https://www.youtube.com/playlist?list=PLpzmRsG7u_gta8p3WGuUq4I1R9apS8Wlg)
- [🔗 OpenAI Cookbook](https://github.com/openai/openai-cookbook)
- [🔗 LangChain Documentation](https://docs.langchain.com/)
- [🔗 Anthropic Claude API Docs](https://docs.anthropic.com/claude)

---

## 📁 Repository Structure


